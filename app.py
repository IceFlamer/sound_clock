import streamlit as st
import numpy as np
from datetime import datetime, date, time, timedelta
import io
from scipy.io.wavfile import write, read
from scipy.fft import rfft, rfftfreq

# ===============================
# –ù–ê–°–¢–†–û–ô–ö–ê
# ===============================
st.set_page_config("üéµ –û—Ä–∫–µ—Å—Ç—Ä –≤—Ä–µ–º–µ–Ω–∏", "üéµ", layout="wide")
SAMPLE_RATE = 44100
BASE_DURATION = 0.8

# ===============================
# SESSION STATE
# ===============================
if "selected_time" not in st.session_state:
    st.session_state.selected_time = datetime.now().time()

# ===============================
# –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ –ü–û –ß–ê–°–ê–ú
# ===============================
HOUR_INSTRUMENTS = {
    range(0, 6):   ("sine", 55),
    range(6, 12):  ("triangle", 110),
    range(12, 18): ("square", 220),
    range(18, 24): ("sawtooth", 110)
}

def instrument_for_hour(hour):
    for r, inst in HOUR_INSTRUMENTS.items():
        if hour in r:
            return inst
    return "sine", 110

# ===============================
# –ì–ï–ù–ï–†–ê–¶–ò–Ø –í–û–õ–ù–´ –° ENVELOPE
# ===============================
def waveform(freq, duration, wave_type):
    t = np.linspace(0, duration, int(SAMPLE_RATE * duration), False)
    n = len(t)
    if wave_type == "sine":
        w = np.sin(2 * np.pi * freq * t)
    elif wave_type == "square":
        w = np.sign(np.sin(2 * np.pi * freq * t))
    elif wave_type == "triangle":
        w = 2 * np.abs(2 * (t * freq - np.floor(t * freq + 0.5))) - 1
    elif wave_type == "sawtooth":
        w = 2 * (t * freq - np.floor(t * freq + 0.5))
    else:
        w = np.sin(2 * np.pi * freq * t)

    # Envelope
    attack = min(int(0.05 * SAMPLE_RATE), n // 2)
    decay = min(int(0.25 * SAMPLE_RATE), n // 2)
    env = np.ones(n)
    if attack > 0:
        env[:attack] = np.linspace(0, 1, attack)
    if decay > 0:
        env[-decay:] = np.linspace(1, 0, decay)
    return w * env

# ===============================
# –ì–ï–ù–ï–†–ê–¶–ò–Ø –ó–í–£–ö–ê
# ===============================
def sound_for_time(t: time):
    h, m, s = t.hour, t.minute, t.second
    wave_type, base = instrument_for_hour(h)
    f_hour = base * (2 ** (h / 12))
    f_min = f_hour * (1 + m / 60)
    f_sec = f_hour * 4

    main = waveform(f_hour, BASE_DURATION, wave_type)
    interval = waveform(f_min, BASE_DURATION, "sine") * 0.6
    pulse = 0.4 if s % 2 == 0 else 0.2
    tick = waveform(f_sec, 0.12, "square") * pulse
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: –∏—Å–ø–æ–ª—å–∑—É–µ–º mode='constant' –≤–º–µ—Å—Ç–æ constant_values (–±–æ–ª–µ–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ)
    tick = np.pad(tick, (0, len(main) - len(tick)), mode='constant')
    signal = main + interval + tick
    signal = signal / (np.max(np.abs(signal)) + 1e-8)
    return signal.astype(np.float32)

# ===============================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø: WAV –í –ë–ê–ô–¢–ê–•
# ===============================
def wav_bytes(signal):
    buf = io.BytesIO()
    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Å–∏–≥–Ω–∞–ª –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [-1, 1] –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ int16
    signal_int16 = np.int16(signal * 32767)
    write(buf, SAMPLE_RATE, signal_int16)
    return buf.getvalue()

# ===============================
# –û–ë–†–ê–¢–ù–´–ô –ê–ù–ê–õ–ò–ó ‚Äî –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô
# ===============================
def infer_time_from_audio(wav_bytes):
    sr, data = read(io.BytesIO(wav_bytes))
    if data.ndim > 1:
        data = data.mean(axis=1).astype(np.float32)
    window = int(BASE_DURATION * sr)
    if len(data) < window:
        return None

    chunk = data[:window]
    spectrum = np.abs(rfft(chunk))
    freqs = rfftfreq(len(chunk), 1 / sr)

    # –ù–∞–π–¥—ë–º –¢–û–ü-3 –ø–∏–∫–∞ (—á—Ç–æ–±—ã –∑–∞—Ö–≤–∞—Ç–∏—Ç—å main + interval)
    peak_indices = np.argsort(spectrum)[-3:][::-1]
    peak_freqs = freqs[peak_indices]
    # –û—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∏ —Ä–∞–∑—É–º–Ω—ã–µ (<2000 –ì—Ü)
    peak_freqs = [f for f in peak_freqs if 20 <= f <= 2000]
    if len(peak_freqs) < 2:
        return None

    # –û—Ç—Å–æ—Ä—Ç–∏—Ä—É–µ–º: –º–µ–Ω—å—à–∞—è —á–∞—Å—Ç–æ—Ç–∞ ‚Äî —á–∞—Å, –±–æ–ª—å—à–∞—è ‚Äî –º–∏–Ω—É—Ç—ã
    f1, f2 = sorted(peak_freqs[:2])

    best_error = float('inf')
    best_time = None

    for hour in range(24):
        wave_type, base = instrument_for_hour(hour)
        f_hour_expected = base * (2 ** (hour / 12))
        for minute in range(60):
            f_min_expected = f_hour_expected * (1 + minute / 60)

            # –û—à–∏–±–∫–∞ –ø–æ –¥–≤—É–º —á–∞—Å—Ç–æ—Ç–∞–º
            err1 = abs(f1 - f_hour_expected)
            err2 = abs(f2 - f_min_expected)
            total_err = err1 + err2

            if total_err < best_error:
                best_error = total_err
                best_time = (hour, minute)

    # –°—É–º–º–∞—Ä–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–æ–ø—É—Å—Ç–∏–º–∞ –¥–æ 12 –ì—Ü (6+6)
    if best_time is None or best_error > 12.0:
        return None

    return best_time

# ===============================
# –ò–ù–¢–ï–†–§–ï–ô–°
# ===============================
st.title("üéµ –û—Ä–∫–µ—Å—Ç—Ä –≤—Ä–µ–º–µ–Ω–∏")
st.caption("–ü—Ä—è–º–æ–π –∏ –æ–±—Ä–∞—Ç–Ω—ã–π –∑–≤—É–∫–æ–≤–æ–π –∫–æ–¥ –≤—Ä–µ–º–µ–Ω–∏")
st.divider()

mode = st.radio("–†–µ–∂–∏–º:", ["–û–¥–Ω–æ –≤—Ä–µ–º—è", "–ó–∞–ø–∏—Å—å –¥–∏–∞–ø–∞–∑–æ–Ω–∞", "–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤—Ä–µ–º—è –ø–æ –∑–≤—É–∫—É"], horizontal=True)

if mode == "–û–¥–Ω–æ –≤—Ä–µ–º—è":
    st.session_state.selected_time = st.time_input("–í—ã–±–µ—Ä–∏—Ç–µ –≤—Ä–µ–º—è", value=st.session_state.selected_time)
    signal = sound_for_time(st.session_state.selected_time)
    if st.button("‚ñ∂Ô∏è –ü—Ä–æ–∏–≥—Ä–∞—Ç—å"):
        st.audio(wav_bytes(signal), format="audio/wav")

elif mode == "–ó–∞–ø–∏—Å—å –¥–∏–∞–ø–∞–∑–æ–Ω–∞":
    t1 = st.time_input("–ù–∞—á–∞–ª–æ", value=time(12, 0, 0))
    t2 = st.time_input("–ö–æ–Ω–µ—Ü", value=time(12, 1, 0))
    step = st.number_input("–®–∞–≥ (—Å–µ–∫)", min_value=1, max_value=10, value=1)
    if st.button("‚è∫ –°–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å—å"):
        cur = datetime.combine(date.today(), t1)
        end = datetime.combine(date.today(), t2)
        chunks = []
        while cur <= end:
            chunks.append(sound_for_time(cur.time()))
            cur += timedelta(seconds=step)
        full = np.concatenate(chunks)
        audio = wav_bytes(full)
        st.audio(audio, format="audio/wav")
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å WAV", audio, "time_recording.wav", mime="audio/wav")

else:  # –û–±—Ä–∞—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ WAV —Ñ–∞–π–ª", type=["wav"])
    if uploaded:
        result = infer_time_from_audio(uploaded.read())
        if result is not None:
            hour, minute = result
            st.success(f"üï∞ –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: **{hour:02d}:{minute:02d}**")
        else:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤—Ä–µ–º—è.")

st.divider()
st.caption("‚ö†Ô∏è –û–±—Ä–∞—Ç–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ ‚Äî –ø—Ä–∏–±–ª–∏–∂—ë–Ω–Ω–æ–µ (FFT-–∞–Ω–∞–ª–∏–∑)")


import streamlit as st
import numpy as np
from datetime import datetime, date, time, timedelta
import plotly.graph_objects as go
import io
from scipy.io.wavfile import write, read
from scipy.fft import rfft, rfftfreq

# ===============================
# –ù–ê–°–¢–†–û–ô–ö–ê
# ===============================
st.set_page_config("üéµ –û—Ä–∫–µ—Å—Ç—Ä –≤—Ä–µ–º–µ–Ω–∏", "üéµ", layout="wide")

SAMPLE_RATE = 44100
BASE_DURATION = 0.8

# ===============================
# SESSION STATE (–ö–õ–Æ–ß–ï–í–û!)
# ===============================
if "selected_time" not in st.session_state:
    st.session_state.selected_time = datetime.now().time()

# ===============================
# –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ –ü–û –ß–ê–°–ê–ú
# ===============================
HOUR_INSTRUMENTS = {
    range(0, 6):  ("sine", 55),
    range(6, 12): ("triangle", 110),
    range(12,18): ("square", 220),
    range(18,24): ("sawtooth", 110)
}

def instrument_for_hour(hour):
    for r, inst in HOUR_INSTRUMENTS.items():
        if hour in r:
            return inst
    return "sine", 110

# ===============================
# –í–û–õ–ù–´ (–ë–ï–ó–û–ü–ê–°–ù–´–ô ENVELOPE)
# ===============================
def waveform(freq, duration, wave_type):
    t = np.linspace(0, duration, int(SAMPLE_RATE * duration), False)
    n = len(t)

    if wave_type == "sine":
        w = np.sin(2*np.pi*freq*t)
    elif wave_type == "square":
        w = np.sign(np.sin(2*np.pi*freq*t))
    elif wave_type == "triangle":
        w = 2*np.abs(2*(t*freq-np.floor(t*freq+0.5)))-1
    elif wave_type == "sawtooth":
        w = 2*(t*freq-np.floor(t*freq+0.5))
    else:
        w = np.sin(2*np.pi*freq*t)

    attack = min(int(0.05*SAMPLE_RATE), n//2)
    decay  = min(int(0.25*SAMPLE_RATE), n//2)

    env = np.ones(n)
    if attack > 0:
        env[:attack] = np.linspace(0,1,attack)
    if decay > 0:
        env[-decay:] = np.linspace(1,0,decay)

    return w * env

# ===============================
# –ó–í–£–ö –î–õ–Ø –í–†–ï–ú–ï–ù–ò
# ===============================
def sound_for_time(t: time):
    h, m, s = t.hour, t.minute, t.second
    wave_type, base = instrument_for_hour(h)

    f_hour = base * 2**(h/12)
    f_min  = f_hour * (1 + m/60)
    f_sec  = f_hour * 4

    main = waveform(f_hour, BASE_DURATION, wave_type)
    interval = waveform(f_min, BASE_DURATION, "sine") * 0.6

    pulse = 0.4 if s % 2 == 0 else 0.2
    tick = waveform(f_sec, 0.12, "square") * pulse
    tick = np.pad(tick, (0, len(main)-len(tick)))

    signal = main + interval + tick
    signal /= np.max(np.abs(signal))

    return signal.astype(np.float32)

# ===============================
# WAV
# ===============================
def wav_bytes(signal):
    buf = io.BytesIO()
    write(buf, SAMPLE_RATE, signal)
    return buf.getvalue()

# ===============================
# –û–ë–†–ê–¢–ù–´–ô –ê–ù–ê–õ–ò–ó –ó–í–£–ö–ê
# ===============================
def infer_time_from_audio(wav_bytes):
    sr, data = read(io.BytesIO(wav_bytes))
    if data.ndim > 1:
        data = data.mean(axis=1).astype(np.float32)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è
    if np.max(np.abs(data)) > 0:
        data = data / np.max(np.abs(data))
    
    window = int(BASE_DURATION * sr)
    base_candidates = [55, 110, 220]
    candidates = []  # —Å–ø–∏—Å–æ–∫ (–æ—à–∏–±–∫–∞, —á–∞—Å, –º–∏–Ω—É—Ç–∞)

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç (–æ–±—ã—á–Ω–æ –µ–≥–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ)
    chunk = data[:window]
    if len(chunk) < window:
        return None

    spectrum = np.abs(rfft(chunk))
    freqs = rfftfreq(len(chunk), 1 / sr)
    peak_idx = np.argmax(spectrum)
    peak_freq = freqs[peak_idx]

    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ base –∏ —á–∞—Å—ã
    for base in base_candidates:
        for hour in range(24):
            f_hour = base * (2 ** (hour / 12))
            # –û–∂–∏–¥–∞–µ–º–∞—è —á–∞—Å—Ç–æ—Ç–∞ –º–∏–Ω—É—Ç–Ω–æ–≥–æ —Ç–æ–Ω–∞
            for minute in range(60):
                f_min_expected = f_hour * (1 + minute / 60)
                error = abs(f_min_expected - peak_freq)
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å –º–∞–ª–æ–π –æ—à–∏–±–∫–æ–π
                if error < 10:  # –¥–æ–ø—É—Å–∫ ¬±10 –ì—Ü ‚Äî –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å
                    candidates.append((error, hour, minute))

    if not candidates:
        return None

    # –í—ã–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –æ—à–∏–±–∫–æ–π
    candidates.sort()
    _, best_hour, best_minute = candidates[0]
    return int(best_hour), int(best_minute)



# ===============================
# UI
# ===============================
st.title("üéµ –û—Ä–∫–µ—Å—Ç—Ä –≤—Ä–µ–º–µ–Ω–∏")
st.caption("–ü—Ä—è–º–æ–π –∏ –æ–±—Ä–∞—Ç–Ω—ã–π –∑–≤—É–∫–æ–≤–æ–π –∫–æ–¥ –≤—Ä–µ–º–µ–Ω–∏")

st.divider()
mode = st.radio("–†–µ–∂–∏–º:", ["–û–¥–Ω–æ –≤—Ä–µ–º—è", "–ó–∞–ø–∏—Å—å –¥–∏–∞–ø–∞–∑–æ–Ω–∞", "–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤—Ä–µ–º—è –ø–æ –∑–≤—É–∫—É"], horizontal=True)

# ===============================
# –û–î–ù–û –í–†–ï–ú–Ø
# ===============================
if mode == "–û–¥–Ω–æ –≤—Ä–µ–º—è":
    st.session_state.selected_time = st.time_input(
        "–í—ã–±–µ—Ä–∏—Ç–µ –≤—Ä–µ–º—è",
        value=st.session_state.selected_time
    )

    signal = sound_for_time(st.session_state.selected_time)

    if st.button("‚ñ∂Ô∏è –ü—Ä–æ–∏–≥—Ä–∞—Ç—å"):
        st.audio(wav_bytes(signal), format="audio/wav")

# ===============================
# –ó–ê–ü–ò–°–¨ –î–ò–ê–ü–ê–ó–û–ù–ê
# ===============================
elif mode == "–ó–∞–ø–∏—Å—å –¥–∏–∞–ø–∞–∑–æ–Ω–∞":
    t1 = st.time_input("–ù–∞—á–∞–ª–æ", time(12,0,0))
    t2 = st.time_input("–ö–æ–Ω–µ—Ü", time(12,1,0))
    step = st.number_input("–®–∞–≥ (—Å–µ–∫)", 1, 10, 1)

    if st.button("‚è∫ –°–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å—å"):
        cur = datetime.combine(date.today(), t1)
        end = datetime.combine(date.today(), t2)

        chunks = []
        while cur <= end:
            chunks.append(sound_for_time(cur.time()))
            cur += timedelta(seconds=step)

        full = np.concatenate(chunks)
        audio = wav_bytes(full)

        st.audio(audio, format="audio/wav")
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å WAV", audio, "time_recording.wav")

# ===============================
# –û–ë–†–ê–¢–ù–´–ô –ê–ù–ê–õ–ò–ó
# ===============================
else:
    uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ WAV —Ñ–∞–π–ª", type=["wav"])
    if uploaded:
        result = infer_time_from_audio(uploaded.read())
        if result is not None:
            hour, minute = result
            st.success(f"üï∞ –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: **{hour:02d}:{minute:02d}**")
        else:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤—Ä–µ–º—è. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω —ç—Ç–∏–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º.")
        st.divider()
        st.caption("‚ö†Ô∏è –û–±—Ä–∞—Ç–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ ‚Äî –ø—Ä–∏–±–ª–∏–∂—ë–Ω–Ω–æ–µ (FFT-–∞–Ω–∞–ª–∏–∑)")




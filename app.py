import streamlit as st
import numpy as np
from datetime import datetime, date, time, timedelta
import io
from scipy.io.wavfile import write, read
from scipy.fft import rfft, rfftfreq
from collections import Counter

# ===============================
# –ù–ê–°–¢–†–û–ô–ö–ê
# ===============================
st.set_page_config("üéµ –û—Ä–∫–µ—Å—Ç—Ä –≤—Ä–µ–º–µ–Ω–∏", "üéµ", layout="wide")
SAMPLE_RATE = 44100
BASE_DURATION = 0.8
BASE_NOTE = 110.0  # A2

# ===============================
# SESSION STATE
# ===============================
if "selected_time" not in st.session_state:
    st.session_state.selected_time = datetime.now().time()

# ===============================
# –í–û–õ–ù–´ –° ENVELOPE
# ===============================
def waveform(freq, duration, wave_type):
    t = np.linspace(0, duration, int(SAMPLE_RATE * duration), False)
    n = len(t)
    if wave_type == "sine":
        w = np.sin(2 * np.pi * freq * t)
    elif wave_type == "square":
        w = np.sign(np.sin(2 * np.pi * freq * t))
    elif wave_type == "triangle":
        w = 2 * np.abs(2 * (t * freq - np.floor(t * freq + 0.5))) - 1
    elif wave_type == "sawtooth":
        w = 2 * (t * freq - np.floor(t * freq + 0.5))
    else:
        w = np.sin(2 * np.pi * freq * t)
    # Envelope
    attack = min(int(0.05 * SAMPLE_RATE), n // 2)
    decay = min(int(0.25 * SAMPLE_RATE), n // 2)
    env = np.ones(n)
    if attack > 0:
        env[:attack] = np.linspace(0, 1, attack)
    if decay > 0:
        env[-decay:] = np.linspace(1, 0, decay)
    return w * env

# ===============================
# –ì–ï–ù–ï–†–ê–¶–ò–Ø –ó–í–£–ö–ê –ü–û –í–†–ï–ú–ï–ù–ò (–ù–û–í–ê–Ø –°–•–ï–ú–ê)
# ===============================
def sound_for_time(t: time):
    h, m, s = t.hour, t.minute, t.second

    # –ß–ê–°: 0‚Äì23 ‚Üí 0‚Äì23 –ø–æ–ª—É—Ç–æ–Ω–∞ –æ—Ç A2
    f_hour = BASE_NOTE * (2 ** (h / 12))

    # –ú–ò–ù–£–¢–´: –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç ‚Üí 1 –ø–æ–ª—É—Ç–æ–Ω (0‚Äì11)
    m_step = (m // 5) % 12
    f_min = BASE_NOTE * (2 ** (m_step / 12))

    # –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–æ–Ω–∞
    tone_h = waveform(f_hour, BASE_DURATION, "sine") * 0.7
    tone_m = waveform(f_min, BASE_DURATION, "sine") * 0.5

    # –°–ï–ö–£–ù–î–´: —Ä–∏—Ç–º ‚Äî (s % 4) + 1 —Ç–∏–∫–æ–≤
    num_ticks = (s % 4) + 1
    tick_signal = np.zeros_like(tone_h)
    for i in range(num_ticks):
        tick = waveform(880, 0.06, "square") * 0.3
        start = int(i * 0.15 * SAMPLE_RATE)
        end = start + len(tick)
        if end <= len(tick_signal):
            tick_signal[start:end] += tick

    signal = tone_h + tone_m + tick_signal
    signal = signal / (np.max(np.abs(signal)) + 1e-6)
    return signal.astype(np.float32)

# ===============================
# WAV –£–¢–ò–õ–ò–¢–´
# ===============================
def wav_bytes(signal):
    buf = io.BytesIO()
    write(buf, SAMPLE_RATE, signal)
    return buf.getvalue()

# ===============================
# –û–ë–†–ê–¢–ù–´–ô –ê–ù–ê–õ–ò–ó (–ù–ê–î–Å–ñ–ù–´–ô)
# ===============================
def infer_time_from_audio(wav_bytes_data):
    sr, data = read(io.BytesIO(wav_bytes_data))
    if data.ndim > 1:
        data = data.mean(axis=1).astype(np.float32)
    
    window = int(BASE_DURATION * sr)
    if len(data) < window:
        return None
    chunk = data[:window]  # –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–µ—Ä–≤–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞

    # –°–ø–µ–∫—Ç—Ä
    spectrum = np.abs(rfft(chunk))
    freqs = rfftfreq(len(chunk), 1 / sr)

    # –ù–∞–π–¥—ë–º –¢–û–ü-2 –ø–∏–∫–∞ (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—á–µ–Ω—å –Ω–∏–∑–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã)
    # –£–±–µ—Ä—ë–º –≤—Å—ë –Ω–∏–∂–µ 50 –ì—Ü
    valid = freqs >= 50
    spectrum = spectrum[valid]
    freqs = freqs[valid]

    # –ù–∞—Ö–æ–¥–∏–º –¥–≤–∞ —Å–∞–º—ã—Ö —Å–∏–ª—å–Ω—ã—Ö –ø–∏–∫–∞
    peak_indices = np.argsort(spectrum)[-2:][::-1]  # –¥–≤–∞ —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö
    peak_freqs = freqs[peak_indices]

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ: –Ω–∏–∂–Ω—è—è ‚Äî —á–∞—Å, –≤–µ—Ä—Ö–Ω—è—è ‚Äî –º–∏–Ω—É—Ç—ã (–æ–±—ã—á–Ω–æ)
    f1, f2 = sorted(peak_freqs[:2])
    candidates = []

    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–∞
    for hour in range(24):
        for minute in range(60):
            f_h_expected = BASE_NOTE * (2 ** (hour / 12))
            f_m_expected = BASE_NOTE * (2 ** ((minute // 5) % 12 / 12))
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –¥–≤—É–º—è –ø–∏–∫–∞–º–∏
            err1 = abs(f1 - f_h_expected) + abs(f2 - f_m_expected)
            err2 = abs(f1 - f_m_expected) + abs(f2 - f_h_expected)  # –Ω–∞ —Å–ª—É—á–∞–π –ø–µ—Ä–µ–ø—É—Ç–∞–Ω–Ω—ã—Ö
            error = min(err1, err2)
            if error < 30:  # –¥–æ–ø—É—Å–∫ ¬±15 –ì—Ü –Ω–∞ –∫–∞–∂–¥—ã–π
                candidates.append((error, hour, minute))

    if not candidates:
        return None

    candidates.sort()
    _, best_hour, best_minute = candidates[0]
    return int(best_hour), int(best_minute)

# ===============================
# UI
# ===============================
st.title("üéµ –û—Ä–∫–µ—Å—Ç—Ä –≤—Ä–µ–º–µ–Ω–∏")
st.caption("–ü—Ä—è–º–æ–π –∏ –æ–±—Ä–∞—Ç–Ω—ã–π –∑–≤—É–∫–æ–≤–æ–π –∫–æ–¥ –≤—Ä–µ–º–µ–Ω–∏ (–º—É–∑—ã–∫–∞–ª—å–Ω–∞—è —Å—Ö–µ–º–∞)")
st.divider()
mode = st.radio("–†–µ–∂–∏–º:", ["–û–¥–Ω–æ –≤—Ä–µ–º—è", "–ó–∞–ø–∏—Å—å –¥–∏–∞–ø–∞–∑–æ–Ω–∞", "–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤—Ä–µ–º—è –ø–æ –∑–≤—É–∫—É"], horizontal=True)

# –û–î–ù–û –í–†–ï–ú–Ø
if mode == "–û–¥–Ω–æ –≤—Ä–µ–º—è":
    st.session_state.selected_time = st.time_input("–í—ã–±–µ—Ä–∏—Ç–µ –≤—Ä–µ–º—è", value=st.session_state.selected_time)
    signal = sound_for_time(st.session_state.selected_time)
    if st.button("‚ñ∂Ô∏è –ü—Ä–æ–∏–≥—Ä–∞—Ç—å"):
        st.audio(wav_bytes(signal), format="audio/wav")

# –ó–ê–ü–ò–°–¨ –î–ò–ê–ü–ê–ó–û–ù–ê
elif mode == "–ó–∞–ø–∏—Å—å –¥–∏–∞–ø–∞–∑–æ–Ω–∞":
    t1 = st.time_input("–ù–∞—á–∞–ª–æ", time(12, 0, 0))
    t2 = st.time_input("–ö–æ–Ω–µ—Ü", time(12, 1, 0))
    step = st.number_input("–®–∞–≥ (—Å–µ–∫)", 1, 10, 1)
    if st.button("‚è∫ –°–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å—å"):
        cur = datetime.combine(date.today(), t1)
        end = datetime.combine(date.today(), t2)
        chunks = []
        while cur <= end:
            chunks.append(sound_for_time(cur.time()))
            cur += timedelta(seconds=step)
        full = np.concatenate(chunks)
        audio = wav_bytes(full)
        st.audio(audio, format="audio/wav")
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å WAV", audio, "time_recording.wav")

# –û–ë–†–ê–¢–ù–´–ô –ê–ù–ê–õ–ò–ó
else:
    uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ WAV —Ñ–∞–π–ª", type=["wav"])
    if uploaded:
        result = infer_time_from_audio(uploaded.read())
        if result is not None:
            hour, minute = result
            st.success(f"üï∞ –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: **{hour:02d}:{minute:02d}**")
        else:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤—Ä–µ–º—è. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω —ç—Ç–∏–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º.")
        st.divider()
        st.caption("‚ö†Ô∏è –û–±—Ä–∞—Ç–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ ‚Äî –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–≤—É—Ö –ø–∏–∫–æ–≤ –∏ –ø–µ—Ä–µ–±–æ—Ä–∞")
